{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mnist-AE.ipynb",
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyN2dKcj1ljFCd0IHEPmNSsS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehdi-or/Variational-AE/blob/master/Mnist_AE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6AWrXH1BR-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Mon May 11 00:00:26 2020\n",
        "\n",
        "@author: sorouji\n",
        "\"\"\"\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "import tensorflow\n",
        "tensorflow.random.set_seed(2)\n",
        "import IPython as IP\n",
        "IP.get_ipython().magic('reset -f')\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras import optimizers\n",
        "from keras.layers import Input, Dense, concatenate, Dropout, Lambda\n",
        "from keras.utils import to_categorical\n",
        "#import pydotplus\n",
        "#from IPython.display import SVG\n",
        "#from keras.utils.vis_utils import model_to_dot\n",
        "from keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import time\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from pandas import DataFrame\n",
        "import os\n",
        "from scipy import stats\n",
        "from keras import backend as K\n",
        "from keras.regularizers import l2\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "#keras.utils.vis_utils.pydotplus = pydotplus\n",
        "from keras.utils.vis_utils import plot_model\n",
        "start = time.time()\n",
        "#%reset -f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzyjvbquBW7j",
        "colab_type": "text"
      },
      "source": [
        "DNN architechture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfeWw8bMBaMM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoding_dim = 12\n",
        "drop = 0.2\n",
        "activation_BT = 'linear'\n",
        "num_epoch = 30\n",
        "lr = 1e-4\n",
        "discription = [str(encoding_dim), activation_BT, str(num_epoch), str(lr)]\n",
        "def nna(encoding_dim):\n",
        "      # this is our input placeholder for VT (creating a tensor)\n",
        "      decoding_vox = Input(shape=(X_train.shape[1],), name=\"VT-input\")\n",
        "\n",
        "      encoded = Dense(512, activation='tanh', name=\"encoded_VT\")(decoding_vox)\n",
        "      encoded= Dropout(drop)(encoded)\n",
        "      \n",
        "      Bneck = Dense(encoding_dim, activation=activation_BT, name=\"Bneck\")(encoded)\n",
        "        \n",
        "      decoded = Dense(512, activation='tanh', name=\"decoded-VT\")(Bneck)\n",
        "      decoded= Dropout(drop)(decoded)\n",
        "      \n",
        "      decoded = Dense(X_train.shape[1], activation='linear', name=\"decoded-output\")(decoded)\n",
        "      decoded= Dropout(drop)(decoded)\n",
        "      \n",
        "\n",
        "      encoder = Model(decoding_vox, Bneck)\n",
        "      decoder = Model(decoding_vox, decoded) # model architecture\n",
        "      plot_model(decoder, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "      \n",
        "      \n",
        "      bn_model = Model(inputs= decoder.input, outputs = decoder.get_layer('Bneck').output)\n",
        "    \n",
        "      # fitting the model and defining loss functiojn for each imput\n",
        "      opt = optimizers.Adam(lr)\n",
        "      decoder.compile(opt, loss='mean_squared_error', metrics=['mse', 'accuracy'])\n",
        "      return decoder, encoder, Bneck, bn_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnSbUo73Bgh7",
        "colab_type": "text"
      },
      "source": [
        "importing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIC8XYDjBlNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train = np.reshape(X_train/255,(X_train.shape[0],X_train.shape[1]**2))\n",
        "X_test = np.reshape(X_test/255,(X_test.shape[0],X_test.shape[1]**2))\n",
        "\n",
        "decoder, encoder, Bneck, bn_model = nna(encoding_dim)\n",
        "decoder.fit(X_train, X_train, epochs= num_epoch, shuffle=True, validation_data=(X_test,X_test))\n",
        "intermediate_layer_model = Model(inputs=decoder.input, outputs=decoder.get_layer('Bneck').output)\n",
        "BottleNeck = intermediate_layer_model.predict(X_test)\n",
        "bt_features = bn_model.predict(X_test)\n",
        "decoded_VT = decoder.predict(X_test)\n",
        "s=int(np.sqrt(decoded_VT.shape[1]))\n",
        "decoded_VT0=np.reshape(decoded_VT,(decoded_VT.shape[0],s,s))\n",
        "X_test0 = np.reshape(X_test,(X_test.shape[0],s,s))\n",
        "plt.imshow(decoded_VT0[0,:,:])\n",
        "plt.figure(2)\n",
        "plt.imshow(X_test0[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCrUUr_gB343",
        "colab_type": "text"
      },
      "source": [
        "classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F58MegSvB8Nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = np.unique(y_test)\n",
        "class_number = len(classes)\n",
        "labels2categ = to_categorical(y_test, num_classes = class_number)\n",
        "\n",
        "BN_feat = Input(shape=(BottleNeck.shape[1],), name=\"BN\")\n",
        "out_class = Dense(classes.shape[0], activation='softmax', name =\"output\", kernel_regularizer=l2(0.007))(BN_feat)\n",
        "classifier = Model(BN_feat, out_class, name='classifier')\n",
        "#chossing the learning rate is very important\n",
        "opt = optimizers.Adam(lr = 5e-5)\n",
        "classifier.compile(opt, loss = 'categorical_crossentropy',  metrics =['accuracy'])\n",
        "\n",
        "#labels2categ = to_categorical(labels2num[0, :], num_classes=len(class_number))\n",
        "history=classifier.fit(BottleNeck, labels2categ, epochs=200, shuffle=True, validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_Bau8lxB-Vw",
        "colab_type": "text"
      },
      "source": [
        "Plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIoh4iSzCADS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(1)\n",
        "plt.plot(np.asarray(history.history['val_accuracy']))\n",
        "plt.plot(np.asarray(history.history['accuracy']))\n",
        "plt.gca().legend(('val_accuracy_decoded','training_accuracy_decoded'), prop={'size': 12})\n",
        "plt.xlabel('num_epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('BN features')\n",
        "\n",
        "plt.figure(2)\n",
        "plt.plot(np.asarray(history.history['val_loss']))\n",
        "plt.plot(np.asarray(history.history['loss']))\n",
        "plt.gca().legend(('val_loss_decoded','training_loss_decoded'), prop={'size': 12})\n",
        "plt.xlabel('no_epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.title('BN features')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}